{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "920ef7bb-0e31-4151-9fb0-50de1141d91e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ffe1f7f4ada8c4a3160626f214fc1e36",
     "grade": false,
     "grade_id": "cell-48cccda20e73351e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Hackathon: From Raw Data to ML-Ready Dataset\n",
    "## Insight-Driven EDA and End-to-End Feature Engineering on Airbnb Data Using pandas and Plotly\n",
    "\n",
    "### What is a Hackathon?\n",
    "\n",
    "A hackathon is a fast-paced, collaborative event where participants use data and technology to solve a real problem end-to-end.  \n",
    "In this hackathon, you will work with a **real-world Airbnb dataset** and complete two interconnected goals:\n",
    "\n",
    "- Produce a **high-quality exploratory data analysis (EDA)** using `pandas` and `plotly`, extracting meaningful insights, trends, and signals from the data.  \n",
    "- Design and deliver a **clean, feature-rich, ML-ready dataset** that will serve as the foundation for a follow-up hackathon focused on building and evaluating machine learning models.\n",
    "\n",
    "Your task is to **get the most out of the data**: uncover structure and patterns through EDA, and engineer informative features (numerical, categorical, temporal, textual (TF–IDF), and optionally image-based) to maximize the predictive power of the final dataset.\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "<b>About the Dataset</b>\n",
    "\n",
    "<u>Context</u>\n",
    "\n",
    "The data comes from <a href=\"https://insideairbnb.com/get-the-data/\">Inside Airbnb</a>, an open project that publishes detailed, regularly updated datasets for cities around the world.  \n",
    "Each city provides three main CSV files:\n",
    "\n",
    "- <b>listings.csv</b> — property characteristics, host profiles, descriptions, amenities, etc.  \n",
    "- <b>calendar.csv</b> — daily availability and pricing information for each listing.  \n",
    "- <b>reviews.csv</b> — guest feedback and textual reviews.\n",
    "\n",
    "These datasets offer a rich view of the short-term rental market, including availability patterns, pricing behavior, host attributes, and guest sentiment.  \n",
    "\n",
    "<u>Inspiration</u>\n",
    "\n",
    "Your ultimate objective is to create a dataset suitable for training a machine learning model that predicts whether a specific Airbnb listing will be <b>available on a given date</b>, using property attributes, review information, and host characteristics.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "<b>Task</b>\n",
    "\n",
    "Using one city of your choice from Inside Airbnb, create an end-to-end pipeline that:\n",
    "\n",
    "1. Loads and explores the raw data (EDA).  \n",
    "2. Engineers features (numerical, categorical, temporal, textual TF–IDF, etc.).  \n",
    "3. Builds a unified ML-ready dataset.  \n",
    "\n",
    "Please remember to add comments explaining your decisions. Comments help us understand your thought process and ensure accurate evaluation of your work. This assignment requires code-based solutions—**manually calculated or hard-coded results will not be accepted**. Thoughtful comments and visualizations are encouraged and will be highly valued.\n",
    "\n",
    "- Write your solution directly in this notebook, modifying it as needed.\n",
    "- Once completed, submit the notebook in **.ipynb** format via Moodle.\n",
    "    \n",
    "<b>Collaboration Requirement: Git & GitHub</b>\n",
    "\n",
    "You must collaborate with your team using a **shared GitHub repository**.  \n",
    "Your use of Git is part of the evaluation. We will specifically look at:\n",
    "\n",
    "- Commit quality (clear messages, meaningful steps).  \n",
    "- Balanced participation across team members.  \n",
    "- Use of branches.  \n",
    "- Ability to resolve merge conflicts appropriately.  \n",
    "- A clean, readable project history that reflects real collaboration.\n",
    "\n",
    "Good Git practice is **part of your grade**, not optional.\n",
    "</div>\n",
    "<div class=\"alert alert-danger\">\n",
    "    You are free to add as many cells as you wish as long as you leave untouched the first one.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "<b>Hints</b>\n",
    "\n",
    "- Text columns often carry substantial predictive power, use text-vectorization methods to extract meaningful features.  \n",
    "- Make sure all columns use appropriate data types (categorical, numeric, datetime, boolean). Correct dtypes help prevent subtle bugs and improve performance.  \n",
    "- Feel free to enrich the dataset with any additional information you consider useful: engineered features, external data, derived temporal features, etc.  \n",
    "- If the dataset is too large for your computer, use <code>.sample()</code> to work with a subset while preserving the logic of your pipeline.  \n",
    "- Plotly offers a wide variety of powerful visualizations, experiment creatively, but always begin with a clear analytical question: *What insight am I trying to uncover with this plot?*\n",
    "\n",
    "</div>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<div class=\"alert alert-danger\">\n",
    "<b>Submission Deadline:</b> Wednesday, December 3rd, 12:00\n",
    "\n",
    "Start with a simple, working pipeline.  \n",
    "Do not over-complicate your code too much. Start with a simple working solution and refine it if you have time.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-danger\">\n",
    "    \n",
    "You may add as many cells as you want, but the **first cell must remain exactly as provided**. Do not edit, move, or delete it under any circumstances.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da41098",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8431230dc8647851888c39d82eb7078d",
     "grade": true,
     "grade_id": "ex1",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# LEAVE BLANK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84467c34-1fa2-4f03-b7ba-e216836ff6b3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7bce797b7aa5f22189e671fd29fa5841",
     "grade": false,
     "grade_id": "cell-140b4c12d85796ac",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Team Information\n",
    "\n",
    "Fill in the information below.  \n",
    "All fields are **mandatory**.\n",
    "\n",
    "- **GitHub Repository URL**: Paste the link to the team repo you will use for collaboration.\n",
    "- **Team Members**: List all student names (and emails or IDs if required).\n",
    "\n",
    "Do not modify the section title.  \n",
    "Do not remove this cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907a430c-3e17-42e4-9b63-3bafd596c383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Team Information (Mandatory) ===\n",
    "# Fill in the fields below.\n",
    "\n",
    "GITHUB_REPO = \"\"       # e.g. \"https://github.com/myteam/airbnb-hackathon\"\n",
    "TEAM_MEMBERS = [\n",
    "    # \"Full Name 1\",\n",
    "    # \"Full Name 2\",\n",
    "    # \"Full Name 3\",\n",
    "]\n",
    "\n",
    "GITHUB_REPO, TEAM_MEMBERS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5723a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting sampling process...\n",
      "Selected 1000 unique listings.\n",
      "\n",
      "--- SAMPLING COMPLETE ---\n",
      "Original Listings: (3679, 79) -> Sample: (1000, 79)\n",
      "Original Calendar: (1342835, 7) -> Sample: (365000, 7)\n",
      "Original Reviews:  (83000, 6) -> Sample: (21615, 6)\n",
      "\n",
      "Files saved in 'data/': listings_sample.csv, calendar_sample.csv, reviews_sample.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "DATA_FOLDER = \"data\"        # Folder where your raw csv.gz files are located\n",
    "N_LISTINGS = 1000           # Number of unique properties to sample\n",
    "SEED = 42                   # Seed for reproducibility (so your team gets the same sample)\n",
    "\n",
    "print(\"Starting sampling process...\")\n",
    "\n",
    "# 1. Load Listings (The \"Parent\" Table)\n",
    "# We start here because we need to select specific IDs first to keep consistency.\n",
    "listings_path = os.path.join(DATA_FOLDER, \"listings.csv.gz\")\n",
    "df_listings = pd.read_csv(listings_path, compression=\"gzip\")\n",
    "\n",
    "# 2. Create the Sample of Listings\n",
    "# We verify if we have enough data before sampling\n",
    "if len(df_listings) > N_LISTINGS:\n",
    "    df_listings_sample = df_listings.sample(n=N_LISTINGS, random_state=SEED)\n",
    "else:\n",
    "    # If the dataset is smaller than the requested sample, take everything\n",
    "    df_listings_sample = df_listings.copy()\n",
    "    \n",
    "# Get the list of IDs we selected. This is the key to filter the other files.\n",
    "selected_ids = df_listings_sample['id'].unique()\n",
    "\n",
    "print(f\"Selected {len(selected_ids)} unique listings.\")\n",
    "\n",
    "# 3. Load and Filter Calendar (The \"Target\" Table)\n",
    "# This file is usually huge, so we filter it to keep only rows for our selected IDs.\n",
    "calendar_path = os.path.join(DATA_FOLDER, \"calendar.csv.gz\")\n",
    "df_calendar_raw = pd.read_csv(calendar_path, compression=\"gzip\")\n",
    "df_calendar_sample = df_calendar_raw[df_calendar_raw['listing_id'].isin(selected_ids)].copy()\n",
    "\n",
    "# 4. Load and Filter Reviews (Text Data)\n",
    "# Same logic: only keep reviews that belong to the selected houses.\n",
    "reviews_path = os.path.join(DATA_FOLDER, \"reviews.csv.gz\")\n",
    "df_reviews_raw = pd.read_csv(reviews_path, compression=\"gzip\")\n",
    "df_reviews_sample = df_reviews_raw[df_reviews_raw['listing_id'].isin(selected_ids)].copy()\n",
    "\n",
    "# 5. Save the Samples\n",
    "# We save them as new files so you don't have to run this heavy process again.\n",
    "df_listings_sample.to_csv(os.path.join(DATA_FOLDER, \"listings_sample.csv\"), index=False)\n",
    "df_calendar_sample.to_csv(os.path.join(DATA_FOLDER, \"calendar_sample.csv\"), index=False)\n",
    "df_reviews_sample.to_csv(os.path.join(DATA_FOLDER, \"reviews_sample.csv\"), index=False)\n",
    "\n",
    "# 6. Verification Output\n",
    "print(\"\\n--- SAMPLING COMPLETE ---\")\n",
    "print(f\"Original Listings: {df_listings.shape} -> Sample: {df_listings_sample.shape}\")\n",
    "print(f\"Original Calendar: {df_calendar_raw.shape} -> Sample: {df_calendar_sample.shape}\")\n",
    "print(f\"Original Reviews:  {df_reviews_raw.shape} -> Sample: {df_reviews_sample.shape}\")\n",
    "print(f\"\\nFiles saved in '{DATA_FOLDER}/': listings_sample.csv, calendar_sample.csv, reviews_sample.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hackathon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
